jobqueue:
  pbs:
    name: dask-worker

    # Dask worker options
    cores: 36                 # Total number of cores per job
    memory: "100 GB"                # Total amount of memory per job
    processes: 9                # Number of Python processes per job

    interface: ib0              # Network interface to use like eth0 or ib0
    death-timeout: 60           # Number of seconds to wait if a worker can not find a scheduler
    local-directory: null       # Location of fast local storage like /scratch or $TMPDIR

    # PBS resource manager options
    queue: regular
    # project: YOUR PROJECT KEY HERE
    walltime: '00:30:00'

distributed:
  dashboard:
    link: http://localhost:8888/proxy/{port}/status
  worker:
    memory:
      target: false  # don't spill to disk
      spill: false  # don't spill to disk
      pause: 0.80  # pause execution at 80% memory use
      terminate: 0.95  # restart the worker at 95% use

